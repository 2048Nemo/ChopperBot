---
title: 如何编写爬虫
date: 2023-07-31 02:05:34
permalink: /pages/63a89d/
---

[[toc]]
## ChopperBot与爬虫

::: tip 简介
如果说插件构成了ChopperBot这颗独特的星球，那么爬虫得到数据则是这颗星球的生命。没有生命的星球将是死气沉沉的，而没有爬虫的ChopperBot也将失去它的光泽
再此向各位开发者介绍如何在ChopperBot中编写一个规范的爬虫并在融合进入ChopperBot中。
:::

如果你不知道什么是爬虫，或者如何编写，请参考下列文章:
- [java爬虫详解及简单实例](https://zhuanlan.zhihu.com/p/634122028)
- [爬虫框架WebMagic](https://webmagic.io/)

## 编写ChopperBot爬虫

### 创建文件夹
```
+-- ChopperBot
|   +-- 模块名
|   |  +-- core
|   |  |  +-- creeper
|   |  |  | +-- loadconfig //爬虫参数文件
|   |  |  | +-- loadtask   //爬虫主体任务
|   |  |  | +-- processor  //后续任务处理
|   +-- 模块名
```

在开始编写爬虫脚本前，请先确保你的模块下的core文件夹中有如上图的几个文件夹，如果已经拥有则可以开始进行爬虫脚本的编写了

### 创建LoadConfig
::: tip 说明
LoadConfig是当前你要进行爬虫时使用的爬虫参数文件，它可以包含url，header，cookie等等信息，**也是爬虫脚本启动的必备文件**
:::

1. 创建一个LoadConfig文件，包含你爬虫需要的必备信息
2. 添加@Creeper注解，将脚本文件交给CreeperCenter管理
```java
@Creeper(creeperName = "豆瓣书籍top250",loadTask = DouBanLoadTask.class,creeperDescription = "爬豆瓣爬的")
public class DouBanLoadConfig extends LoadConfig {
    public DouBanLoadConfig() {
        this.url = "https://book.douban.com/top250"; //爬虫url
        //this.UserAgent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36";
        //this.Origin = "https://live.bilibili.com";
        //this.Referer = "https://live.bilibili.com/";
    }
}
```
LoadConfig的其他参数
```java
String url;
String startTime;
String UserAgent;
String Origin;
String Referer;
Map<String,String> header;  //头信息
Map<String,String> cookie;  //Cookie
```
如果你需要更多参数可以继承LoadConfig，自行添加，例如下面代码：
```java
public abstract class LoadVideoConfig extends LoadConfig {
    protected String videoPath;

    // 视频保存名称
    protected String videoName;

    protected int clarity;

    public LoadVideoConfig(String videoPath, String videoName) {
        this.videoPath = videoPath;
        this.videoName = videoName;
    }
}
```
### 创建LoadTask
::: tip 说明
LoadTask就是整个爬虫文件运行的核心，他负责读取LoadConfig中的数据，并进行爬虫！启动！**是爬虫脚本启动的必备文件**，
在ChopperBot也提供了多种LoadTask类型的编写，目前结合了WebMagic框架，之后会结合更多爬虫框架。
:::
编写一个最简单的脚本
```java
/**
 * 网上随便找的个爬豆瓣的demo，需要导入jsoup，不清楚能不能运行
 * 链接：https://www.w3cschool.cn/article/69979497.html
 */
public class DouBanLoadTask extends CommonLoadTask<ArrayList<Book>> {
    

    public DouBanLoadTask(DouyuBanLoadConfig loadConfig) {
        super(loadConfig);
    }

    @Override
    public ArrayList<Book> start() {
        try {
            // 连接到URL，并获取网页的文档对象
            Document doc = Jsoup.connect(loadConfig.getUrl()).get();
            // 选择所有包含书籍信息的元素
            Elements elements = doc.select("div.article > div.indent > table");
            // 遍历每个元素
            for (Element element : elements) {
                // 提取书籍的标题
                String title = element.select("div.pl2 > a").attr("title");
                // 提取书籍的作者
                String author = element.select("p.pl").text().split("/")[0];
                // 提取书籍的评分
                String rating = element.select("span.rating_nums").text();
                // 提取书籍的简介
                String summary = element.select("span.inq").text();
                // 创建一个Book对象
                Book book = new Book(title, author, rating, summary);
                // 将Book对象添加到列表中
                books.add(book);
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
        return books;
    }

    @Override
    public void end() {

    }
    
    class Book{
        private String title; // 标题
        private String author; // 作者
        private String rating; // 评分
        private String summary; // 简介


        // 书籍的构造方法
        public Book(String title, String author, String rating, String summary) {
            this.title = title;
            this.author = author;
            this.rating = rating;
            this.summary = summary;
        }

    }
}

```

#### 其他的LoadTask

- **CommonLoadTask**:
无特殊需求无框架的LoadTask，适用于编写所有类型的爬虫脚本
- **WebMagicLoadTask**:
基于WebMagic框架开发的LoadTask，适用于快速开发多线程，深度广度等多种爬虫策略的LoadTask
> 1. 创建Spider
> ```SpiderFactory.buildSpider(平台名称,Processor,url)```
> 2. 获取最终结果
> ```Object obj = getData(spider,url)```
> ```java
>  @Override
>    public List<DouyuLive> start(){
>       
>        List<DouyuLive> lives;
>       
>        Spider spider = SpiderFactory.buildSpider(ConstPool.PLATFORM.DOUYU.getName(), //平台名称
>                douyuHotLiveProcessor, //processor
>                loadConfig.getUrl());  //url
>        try {
>            lives = getData(spider,loadConfig.getUrl());
>        }catch (Exception e){
>            fail(e);
>            return null;
>        }
>        success();
>        return lives;
>    }
> ```
- ~~AsyncLoadTask（不完善，不推荐使用）~~:
异步的LoadTask，用于异步运行的爬虫脚本，得到的结果需要提供给result

**至此你的爬虫脚本就编写完毕了，无需额外的学习，你可以当作写一个算法OR一个面向过程的程序，总之想要编写一个爬虫脚本很简单。除了创建几个必要的文件外和一行注释外，你只需要写下你的脚本代码即可**

## 爬虫运行中心
::: tip 说明
如果你已经完成一个可以单独运行的爬虫脚本。你可以将你写好的爬虫脚本放入[TaskCenter](/pages/691628/)中来进行爬虫脚本的运行管理，监控，调度，以及本地存储，失败恢复等功能。
:::
```java
CommonPlugin plugin = InitPluginRegister.getPlugin(PluginName.TASK_CENTER_PLUGIN); //获取TaskCenter插件
        
ReptileRequest request =  new ReptileRequest(new DouyuHotModuleConfig(),  //需要调度爬虫方法的参数文件
(t)->{System.out.println("return val:"+t)}        //爬虫任务完成后的callback方法
)
        
((TaskCenter)plugin).request(request);
```
以上代码分为以下几点：
1. `TaskCenter`插件已经启动，并获取
2. 构建`ReptileRequest`
3. 放入需要爬虫方法的文件，文件要确保有对应的`LoadTask`
4. 编写`CallBack`方法，这个是在`LoadTask`调用结束并返回值时执行的，t为返回的值，你可以自行处理返回的值
5. 发送爬虫请求给`TaskCenter`运行

## 爬虫脚本库
当你需要跨模块调用或者快捷使用爬虫脚本时，你可以在`CreeperManger`插件中查找你已经注解`@Creeper`的爬虫脚本
```java
CreeperManager manager = InitPluginRegister.getPlugin(PluginName.CREEPER_MANAGER_PLUGIN); //获取CreeperManager插件
//根据名字获取爬虫脚本
LoadTask task1 = manager.getLoadTask("豆瓣脚本")
//根据爬虫请求中的LoadConfig获得爬虫脚本
LoadTask task2 = manager.getLoadTask(ReptileRequest)

```
